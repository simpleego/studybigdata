# **특징 선택(feature selection)** 기법
> 특징 선택 기법은 모델 성능을 높이고 과적합을 줄이는 데 매우 중요하죠.
> 그 중에서도 **래퍼(Wraper) 기법**과 **임베디드(Embedded) 기법**은 모델 기반의 특징 선택 방식인데, 접근 방식과 효율성에서 차이가 있음  

- Wrapper Method
- Embedded Method

---

## 🧪 1. 래퍼 기법 (Wrapper Method)

### ✅ 개념
- **모델을 반복적으로 학습**하면서 다양한 특징 조합을 평가
- 특징 선택이 **모델 성능에 직접적으로 의존**

### ✅ 방식
- 특징 집합을 선택 → 모델 학습 → 성능 평가 → 최적 조합 탐색
- 예: **순방향 선택**, **후방 제거**, **유전 알고리즘**

### ✅ 장점
- 모델 성능 기준으로 선택하므로 **정확도 높음**
- 특정 모델에 최적화된 특징 조합 가능

### ✅ 단점
- **계산 비용이 매우 큼** (모델을 여러 번 학습해야 함)
- 과적합 위험 있음

---

## 🧬 2. 임베디드 기법 (Embedded Method)

### ✅ 개념
- 특징 선택이 **모델 학습 과정에 포함됨**
- 모델이 학습하면서 **자동으로 중요 특징을 선택**

### ✅ 방식
- 모델의 내부 구조나 규제(regularization)를 활용
- 예:  
  - **Lasso 회귀** → L1 정규화로 중요하지 않은 특징의 계수를 0으로 만듦  
  - **트리 기반 모델** → 특징 중요도(feature importance) 계산

### ✅ 장점
- **속도 빠름** (모델 학습과 특징 선택이 동시에 진행됨)
- 과적합 방지에 효과적

### ✅ 단점
- 특정 모델에 종속적 (예: Lasso는 선형 모델에만 적용 가능)
- 모델이 잘못된 특징을 선택할 수도 있음

---

## 📊 비교 요약

| 항목 | 래퍼 기법 | 임베디드 기법 |
|------|-----------|----------------|
| 특징 선택 시점 | 모델 학습 **외부** | 모델 학습 **내부** |
| 계산 비용 | 높음 | 낮음 |
| 성능 | 높을 수 있음 | 효율적이고 안정적 |
| 과적합 위험 | 있음 | 낮음 |
| 예시 | 순방향 선택, 후방 제거 | Lasso, 트리 기반 모델 |

---

## 💡 선택 팁

- **데이터가 작고 정확도가 중요**하다면 → 래퍼 기법  
- **데이터가 크고 효율이 중요**하다면 → 임베디드 기법  
- **빠른 프로토타입**에는 필터 기법도 고려 가능 (예: 상관계수, 카이제곱)

---
