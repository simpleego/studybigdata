# 노름(Norm)
> 수학이나 데이터 과학에서 자주 등장하지만,
> 그 **원어적 의미**를 이해하면 개념이 훨씬 더 명확해진다.

---

## 🧾 "Norm"의 원어적 의미

### ✅ 어원

- **라틴어 "norma"**에서 유래  
  - 의미: **자**, **규범**, **표준**
  - 원래는 목수들이 쓰던 **직각 자**를 뜻했어요

### ✅ 영어에서의 일반적 의미

- **"Standard"**, **"Rule"**, **"Pattern"**  
- 즉, 어떤 대상의 **크기나 기준을 정하는 방식**

---

## 📐 수학에서의 의미

수학에서는 "Norm"이란:

> 어떤 **벡터나 함수의 크기(길이)** 를 측정하는 **함수 또는 규칙**

즉, 벡터 공간에서 "이 벡터가 얼마나 큰가?"를 정량적으로 표현하는 방식이에요.

예를 들어:

- **L1 Norm**: 절댓값의 합 → Manhattan 거리  
- **L2 Norm**: 제곱합의 제곱근 → Euclidean 거리  
- **∞ Norm**: 가장 큰 절댓값 → Max Norm

---

## 📊 데이터 과학에서의 의미

- **정규화(normalization)** 에서 사용됨  
  - 데이터를 일정한 크기로 맞추기 위해 **Norm을 기준으로 나눔**
- 예:  
$\text{Normalized vector} = \frac{\vec{x}}{\|\vec{x}\|}$

---

## 🧠 요약

| 구분 | 의미 |
|------|------|
| 어원 | 라틴어 "norma" → 자, 기준 |
| 일반 영어 | 규범, 표준 |
| 수학 | 벡터의 크기를 측정하는 함수 |
| 데이터 과학 | 정규화 기준으로 사용됨 |

---

"Norm"은 단순한 수학 기호가 아니라, **무언가를 측정하고 비교하기 위한 기준**이라는 철학적 의미도 담고 있음  

---

## 📐 L1 Norm vs L2 Norm: 차이점

| 항목 | L1 Norm (Manhattan Norm) | L2 Norm (Euclidean Norm) |
|------|---------------------------|----------------------------|
| 정의 | 벡터 성분의 **절댓값 합** | 벡터 성분의 **제곱합의 제곱근** |
| 거리 개념 | **직선 거리** (도시 블록처럼) | **직선 거리** (직선으로 잰 거리) |
| 특징 | 희소성 유지, 이상치에 덜 민감 | 부드러운 최적화, 이상치에 민감 |
| 사용 예 | Lasso Regression, 희소 모델 | Ridge Regression, 일반적인 거리 계산 |

**수식 정리**  
```math
L1 Norm  :   ||x||_1 = \sum_{i=1}^{n} |x_i|
```  
```math
L2 Norm  : ||x||_2 = \sqrt{\sum_{i=1}^{n} x_i^2}
```  

---

## ✏️ 예시: 벡터 \(\vec{x} = [3, 4]\)

**L1 Norm**  
$\|\vec{x}\|_1 = |3| + |4| = 7$

**L2 Norm**  
$\|\vec{x}\|_2 = \sqrt{3^2 + 4^2} = \sqrt{9 + 16} = \sqrt{25} = 5$


---

## 🧠 실제 적용 예시

### 1. **머신러닝 정규화**

- **L1 정규화 (Lasso Regression)**  
  - 모델이 **불필요한 변수의 계수를 0으로 만들어** 희소한 모델 생성  
  - 변수 선택에 유리

- **L2 정규화 (Ridge Regression)**  
  - 모든 변수의 계수를 **작게 유지**  
  - 과적합 방지에 효과적

---

### 2. **이미지 처리**

- 이미지 간 유사도 측정 시:
  - **L1 Norm**: 픽셀 차이의 총합 → 이상치에 덜 민감  
  - **L2 Norm**: 픽셀 차이의 제곱합 → 더 정확하지만 이상치에 민감

---

### 3. **로봇 경로 계산**

- **L1 거리**: 로봇이 격자형 길을 따라 움직일 때 (좌우, 상하만 가능)  
- **L2 거리**: 로봇이 대각선도 포함해 자유롭게 움직일 수 있을 때

---

## 🎯 요약

- **L1 Norm**: 희소성, 이상치에 강함  
- **L2 Norm**: 부드러운 최적화, 일반적인 거리 계산  
- 선택은 **문제의 특성**에 따라 달라짐  

---

